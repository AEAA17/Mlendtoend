# Previs√£o de Valores de Im√≥veis na Calif√≥rnia üè°
### Este projeto utiliza aprendizado de m√°quina para prever o valor m√©dio de im√≥veis em distritos da Calif√≥rnia, utilizando um conjunto de dados com caracter√≠sticas geogr√°ficas, demogr√°ficas e econ√¥micas. Baseado no livro de Aur√©lien G√©ron, M√£os √° Obras: Aprendizado de M√°quina com Scikit-Learn, Keras & TensorFlow, este projeto explora o pipeline completo de um modelo de aprendizado de m√°quina, desde a an√°lise explorat√≥ria at√© a avalia√ß√£o do modelo final.

# Objetivo

### Desenvolver modelos preditivos para estimar os pre√ßos m√©dios de im√≥veis e analisar o desempenho de diferentes algoritmos de aprendizado de m√°quina, como regress√£o linear, √°rvores de decis√£o e florestas aleat√≥rias.

# Estrutura do Projeto
### 1. Carregamento e Visualiza√ß√£o dos Dados
### O conjunto de dados √© carregado e analisado inicialmente para compreender suas caracter√≠sticas e detectar poss√≠veis problemas, como dados faltantes ou desbalanceamentos.

### 2. Explora√ß√£o dos Dados 
### Inclui an√°lises de correla√ß√£o, cria√ß√£o de novos atributos e visualiza√ß√µes para entender melhor os fatores que influenciam o pre√ßo dos im√≥veis.

### 3. Prepara√ß√£o dos Dados
### Foi constru√≠do um pipeline para pr√©-processamento dos dados, incluindo tratamento de valores ausentes, escalonamento de vari√°veis e codifica√ß√£o de categorias.

### 4. Treinamento e Avalia√ß√£o de Modelos
### Foram avaliados os modelos de Regress√£o Linear, √Årvore de Decis√£o e Floresta Aleat√≥ria, comparando m√©tricas como RMSE e MAE.

### 5. Otimiza√ß√£o de Hiperpar√¢metros
### Utilizou-se Grid Search para otimizar os par√¢metros do modelo de Floresta Aleat√≥ria, alcan√ßando uma melhora significativa no desempenho.

# Bibliotecas Utilizadas

```
import pandas as pd
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from scipy.stats import randint
from scipy import stats
import joblib
```


## Carregando e verificando dados:
```
# Carregando o dataset do arquivo "housing.csv" disponibilizado no reposit√≥rio de Aur√©lien G√©ron:
# Link: https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb
df = pd.read_csv("housing.csv")

# Visualizando as primeiras linhas do DataFrame para inspecionar a estrutura e os dados
print(df)  # O DataFrame possui 10 colunas: 9 num√©ricas e 1 categ√≥rica ('ocean_proximity')

# Exibindo informa√ß√µes gerais do DataFrame, como tipos de dados e valores ausentes
df.info()  
# Observa√ß√£o: Todas as colunas est√£o com os tipos de dados corretos.
# A coluna 'total_bedrooms' cont√©m valores ausentes.

# Gerando um resumo estat√≠stico das colunas num√©ricas
print(df.describe())

# Exibindo a contagem de cada categoria na coluna categ√≥rica 'ocean_proximity'
print(df["ocean_proximity"].value_counts())  
# Observa√ß√£o: A coluna categ√≥rica possui 5 categorias distintas.

# Criando histogramas para as colunas num√©ricas do DataFrame
df.hist(bins=50, figsize=(20, 15))
plt.show()
```
![histogramas para as colunas num√©ricas do DataFrame]([images/histogramas_para_as_colunas num√©ricas_do_DataFrame.png](https://github.com/AEAA17/Mlendtoend/blob/76e10335552c917f5e63e2ecf586c745943b8452/images/histogramas%20para%20as%20colunas%20num%C3%A9ricas%20do%20DataFrame.png))

```
# Observa√ß√µes adicionais:
# - A coluna 'median_income' n√£o representa a renda em d√≥lares, mas foi dimensionada (valores v√£o de 0.5 a 15).
#   Esse problema ser√° tratado posteriormente por meio de estratifica√ß√£o.
# - As colunas 'housing_median_age' e 'median_house_value' tamb√©m est√£o dimensionadas.
# - A vari√°vel 'median_house_value', que ser√° nossa vari√°vel-alvo, apresenta um problema: valores limite (capping).
```
##  Explorando e Visualizando os dados do df:
```
# Exibindo a distribui√ß√£o geogr√°fica dos im√≥veis com base na longitude e latitude.
# O par√¢metro alpha reduz a opacidade dos pontos para facilitar a visualiza√ß√£o da densidade de dados.
df.plot(kind="scatter", x="longitude", y="latitude", alpha=0.1) 
plt.show()

![distribui√ß√£o geogr√°fica dos im√≥veis](images/grafico.png)

# Observa√ß√£o: Os dados est√£o concentrados principalmente em √°reas como S√£o Francisco, Los Angeles, San Diego, Sacramento e Fresno.

# Comparando dados geogr√°ficos com o pre√ßo dos im√≥veis
# Representando a localiza√ß√£o geogr√°fica e adicionando vari√°veis contextuais:
# - O tamanho dos pontos (par√¢metro s) √© proporcional √† popula√ß√£o (dividida por 100 para ajuste).
# - A cor dos pontos (par√¢metro c) representa o valor m√©dio dos im√≥veis, com um mapa de cores cont√≠nuo (cmap).
# - O colorbar √† direita indica a escala de valores.
df.plot(
    kind="scatter",
    x="longitude",
    y="latitude",
    alpha=0.4, 
    s=df["population"] / 100,
    label="Population",
    figsize=(10, 7),
    c="median_house_value",
    cmap=plt.get_cmap("jet"),
    colorbar=True,
    sharex=False
)
plt.show()

# Observa√ß√£o: As maiores rendas se concentram em √°reas como S√£o Francisco e Los Angeles, evidenciando uma correla√ß√£o entre o valor dos im√≥veis e a localiza√ß√£o.

![Comparando dados geogr√°ficos com o pre√ßo dos im√≥veis](images/grafico.png)
```

## Buscando correla√ß√µes
```
# Calculando a matriz de correla√ß√£o para as colunas num√©ricas
# A fun√ß√£o `corr` calcula a correla√ß√£o de Pearson entre as vari√°veis num√©ricas no DataFrame.
# Em seguida, filtramos as correla√ß√µes relacionadas √† vari√°vel "median_house_value" e as ordenamos em ordem decrescente.
corr_matrix = df.corr(numeric_only=True)
corr_matrix["median_house_value"].sort_values(ascending=False)
print(corr_matrix)

# Visualizando a correla√ß√£o entre m√∫ltiplas vari√°veis
# Selecionamos atributos relevantes para an√°lise e utilizamos a fun√ß√£o `scatter_matrix` para criar gr√°ficos de dispers√£o.
# Esses gr√°ficos mostram a rela√ß√£o entre "median_house_value", "median_income", "total_rooms" e "housing_median_age".
attributes = ["median_house_value", "median_income", "total_rooms", "housing_median_age"]
scatter_matrix(df[attributes], figsize=(12, 8))
plt.show()

![correla√ß√£o entre m√∫ltiplas vari√°veis](images/grafico.png)

# Observa√ß√£o: A vari√°vel mais correlacionada ao pre√ßo do im√≥vel ("median_house_value") √© a renda m√©dia ("median_income").
# Vamos explorar essa correla√ß√£o em mais detalhes com um gr√°fico de dispers√£o.

# Criando um gr√°fico de dispers√£o para analisar a rela√ß√£o entre "median_income" e "median_house_value".
# - O par√¢metro `alpha` ajusta a transpar√™ncia dos pontos para evitar sobreposi√ß√£o excessiva.
# - `plt.axis` define os limites para os eixos, com a faixa de valores observada no dataset.
df.plot(kind="scatter", x="median_income", y="median_house_value", alpha=0.4)
plt.axis([0, 16, 0, 550000])
plt.show()

![gr√°fico de dispers√£o para analisar a rela√ß√£o entre "median_income" e "median_house_value"](images/grafico.png)

# Observa√ß√µes:
# - O gr√°fico mostra uma tend√™ncia ascendente clara: quanto maior a renda m√©dia, maior o pre√ßo do im√≥vel.
# - H√° um limite m√°ximo de USD 500 mil, o que resulta em uma linha reta horizontal nesse valor, indicando uma restri√ß√£o nos dados.
# - Linhas retas adicionais em valores como 450 mil e 350 mil sugerem outras restri√ß√µes ou caracter√≠sticas no conjunto de dados.

```
##  Explorando mais correla√ß√µes 
```
# Criando novas vari√°veis derivadas para enriquecer a an√°lise:
# - "rooms_per_household": m√©dia de c√¥modos por resid√™ncia.
# - "bedrooms_per_room": propor√ß√£o de quartos entre o total de c√¥modos.
# - "population_per_household": n√∫mero m√©dio de pessoas por resid√™ncia.
df["rooms_per_household"] = df["total_rooms"] / df["households"]  
df["bedrooms_per_room"] = df["total_bedrooms"] / df["total_rooms"]
df["population_per_household"] = df["population"] / df["households"]

# Calculando novamente a matriz de correla√ß√£o para incluir as novas vari√°veis.
corr_matrix = df.corr(numeric_only=True)

# Ordenando as correla√ß√µes com a vari√°vel-alvo ("median_house_value") em ordem decrescente.
print(corr_matrix["median_house_value"].sort_values(ascending=False))

# Observa√ß√µes sobre os resultados:
# - **rooms_per_household**: possui uma correla√ß√£o positiva com "median_house_value". Isso sugere que im√≥veis com mais c√¥modos por resid√™ncia tendem a ser mais caros.
# - **bedrooms_per_room**: apresenta uma correla√ß√£o negativa mais forte. Isso indica que, quanto maior a propor√ß√£o de quartos em rela√ß√£o ao total de c√¥modos, menor √© o valor do im√≥vel.
# - **population_per_household**: mostra uma correla√ß√£o negativa fraca, sugerindo que a densidade populacional por resid√™ncia tem pouca influ√™ncia no pre√ßo dos im√≥veis.

```


## Defini√ß√£o das vari√°veis auxiliares e Constru√ß√£o do pipeline
```
# Selecionando as colunas relevantes para c√°lculos personalizados.
col_names = ["total_rooms", "total_bedrooms", "population", "households"]

# Identificando os √≠ndices das colunas no DataFrame, para refer√™ncia no pipeline.
rooms_ix, bedrooms_ix, population_ix, households_ix = [
    df.columns.get_loc(c) for c in col_names
]

# Defini√ß√£o de uma classe personalizada para adicionar atributos combinados ao conjunto de dados.
class CombinedAttributesAdder(BaseEstimator, TransformerMixin):
    def __init__(self, add_bedrooms_per_room=True):  # Par√¢metro para decidir incluir "bedrooms_per_room".
        self.add_bedrooms_per_room = add_bedrooms_per_room

    def fit(self, X, y=None):  # M√©todo fit (obrigat√≥rio em classes do scikit-learn). Retorna o pr√≥prio objeto.
        return self

    def transform(self, X):  # M√©todo transform para criar novos atributos.
        # Calcula atributos derivados: c√¥modos por resid√™ncia e popula√ß√£o por resid√™ncia.
        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]
        population_per_household = X[:, population_ix] / X[:, households_ix]
        
        # Condicional para adicionar "bedrooms_per_room" apenas se especificado.
        if self.add_bedrooms_per_room:
            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]
            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]
        else:
            return np.c_[X, rooms_per_household, population_per_household]

# Constru√ß√£o de um pipeline para pr√©-processamento de dados num√©ricos.
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="median")),  # Preenche valores ausentes com a mediana.
    ('attribs_adder', CombinedAttributesAdder()),  # Adiciona atributos combinados.
    ('std_scaler', StandardScaler()),  # Padroniza os dados num√©ricos (m√©dia = 0, desvio padr√£o = 1).
])

# Criando categorias de renda para estratifica√ß√£o dos dados.
df["income_cat"] = pd.cut(
    df["median_income"], 
    bins=[0., 1.5, 3.0, 4.5, 6., np.inf],  # Define os intervalos das categorias.
    labels=[1, 2, 3, 4, 5]  # Nomeia as categorias de 1 a 5.
)

# Realizando uma divis√£o estratificada com base nas categorias de renda.
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(df, df["income_cat"]):
    strat_train_set = df.loc[train_index]  # Conjunto de treino estratificado.
    strat_test_set = df.loc[test_index]  # Conjunto de teste estratificado.

# Separando os atributos (features) e o r√≥tulo (label) no conjunto de treino.
housing_features = strat_train_set.drop(["median_house_value", "income_cat"], axis=1)  # Atributos.
housing_labels = strat_train_set["median_house_value"].copy()  # R√≥tulo.

# Reutilizando o pipeline para processar os atributos num√©ricos.
num_attribs = housing_features.select_dtypes(include=[np.number]).columns  # Atributos num√©ricos.
cat_attribs = ["ocean_proximity"]  # Atributo categ√≥rico.

# Constru√ß√£o de um pipeline completo para processar dados num√©ricos e categ√≥ricos.
full_pipeline = ColumnTransformer([
    ("num", num_pipeline, num_attribs),  # Pipeline para atributos num√©ricos.
    ("cat", OneHotEncoder(), cat_attribs),  # Codifica√ß√£o one-hot para atributos categ√≥ricos.
])

# Aplicando o pipeline completo para preparar os dados.
housing_prepared = full_pipeline.fit_transform(housing_features)

# Verificando a forma do conjunto de dados processado.
print(housing_prepared.shape)
```
## Treinando e avaliando modelos
```
# Instanciando o modelo de Regress√£o Linear.
lin_reg = LinearRegression()

# Treinando o modelo com os dados preparados e os r√≥tulos (valores reais).
lin_reg.fit(housing_prepared, housing_labels)
LinearRegression()

# Selecionando um pequeno conjunto de dados para teste (5 primeiras linhas do DataFrame original).
some_data = df.iloc[:5]  # Conjunto de dados de exemplo.
some_labels = housing_labels.iloc[:5]  # R√≥tulos correspondentes ao conjunto de exemplo.

# Aplicando o pipeline completo para preparar o conjunto de dados de exemplo.
some_data_prepared = full_pipeline.transform(some_data)

# Fazendo previs√µes no conjunto de dados de exemplo.
print("Predictions:", lin_reg.predict(some_data_prepared))  # Valores previstos pelo modelo.
print("Labels:", list(some_labels))  # R√≥tulos reais para compara√ß√£o.

# Realizando previs√µes em todo o conjunto de treinamento.
housing_predictions = lin_reg.predict(housing_prepared)

# Calculando o erro quadr√°tico m√©dio (MSE) das previs√µes no conjunto de treinamento.
lin_mse = mean_squared_error(housing_labels, housing_predictions)

# Calculando a raiz do erro quadr√°tico m√©dio (RMSE) para interpreta√ß√£o mais intuitiva.
lin_rmse = np.sqrt(lin_mse)
print("Root Mean Squared Error (RMSE):", lin_rmse)

# Calculando o erro absoluto m√©dio (MAE) para avaliar as diferen√ßas absolutas entre previs√µes e r√≥tulos.
lin_mae = mean_absolute_error(housing_labels, housing_predictions)
print("Mean Absolute Error (MAE):", lin_mae)

# Observa√ß√£o: O RMSE e o MAE s√£o altos em compara√ß√£o √† faixa de valores de pre√ßo m√©dio das casas 
# (aproximadamente 120.000 a 265.000). Isso indica que o modelo de regress√£o linear simples n√£o tem
# precis√£o suficiente e pode n√£o ser adequado para este problema.
```

## Modelo de Arvore de decis√£o
```
# Instanciando o modelo de √Årvore de Decis√£o.
tree_reg = DecisionTreeRegressor(random_state=42)

# Treinando o modelo com os dados preparados e os r√≥tulos (valores reais).
tree_reg.fit(housing_prepared, housing_labels)

# Fazendo previs√µes no conjunto de treinamento.
housing_predictions = tree_reg.predict(housing_prepared)

# Calculando o erro quadr√°tico m√©dio (MSE) e a raiz do erro quadr√°tico m√©dio (RMSE).
tree_mse = mean_squared_error(housing_labels, housing_predictions)
tree_rmse = np.sqrt(tree_mse)
print("Tree RMSE (Treinamento):", tree_rmse)

# Observa√ß√£o: Um RMSE de 0 ou pr√≥ximo de 0 no conjunto de treinamento √© extremamente raro e sugere que o modelo
# pode estar superajustado (overfitting), ou seja, aprendendo detalhes espec√≠ficos dos dados de treinamento em vez
# de padr√µes generaliz√°veis. Para avaliar melhor o desempenho, usamos valida√ß√£o cruzada.

# Valida√ß√£o cruzada com 10 divis√µes para avaliar o desempenho do modelo de forma mais robusta.
scores = cross_val_score(tree_reg, housing_prepared, housing_labels, 
                         scoring="neg_mean_squared_error", cv=10)

# Convertendo os scores para valores positivos e calculando o RMSE.
tree_rmse_scores = np.sqrt(-scores)

# Fun√ß√£o para exibir m√©tricas de desempenho.
def display_scores(scores):
    print("Scores em cada rodada de valida√ß√£o cruzada:", scores)
    print("M√©dia dos scores:", scores.mean())
    print("Desvio padr√£o dos scores:", scores.std())

# Exibindo os resultados da valida√ß√£o cruzada para a √Årvore de Decis√£o.
display_scores(tree_rmse_scores)

# Observa√ß√£o: Apesar de a √Årvore de Decis√£o parecer muito boa no treinamento (RMSE pr√≥ximo de 0),
# a valida√ß√£o cruzada mostra um desempenho consideravelmente pior, com m√©dia de RMSE de aproximadamente 71.629 
# e desvio padr√£o de 2.914. 

# Avaliando o modelo de Regress√£o Linear com valida√ß√£o cruzada para compara√ß√£o.
lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, 
                             scoring="neg_mean_squared_error", cv=10)

# Convertendo os scores para valores positivos e calculando o RMSE.
lin_rmse_scores = np.sqrt(-lin_scores)

# Exibindo os resultados da valida√ß√£o cruzada para o modelo de Regress√£o Linear.
display_scores(lin_rmse_scores)

# Observa√ß√£o: Comparando os resultados, o modelo de Regress√£o Linear apresenta um desempenho mais consistente, 
# com uma m√©dia de RMSE de aproximadamente 69.104 e desvio padr√£o de 2.880. Isso sugere que, embora o modelo de 
# Regress√£o Linear n√£o seja perfeito, ele generaliza melhor do que a √Årvore de Decis√£o.
```

## Modelo Floresta Randomica 
```
# Instanciando o modelo de Floresta Aleat√≥ria com 100 estimadores (√°rvores) e semente para reprodutibilidade.
forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)

# Treinando o modelo com os dados preparados e os r√≥tulos (valores reais).
forest_reg = forest_reg.fit(housing_prepared, housing_labels)

# Fazendo previs√µes no conjunto de treinamento.
housing_predictions = forest_reg.predict(housing_prepared)

# Calculando o erro quadr√°tico m√©dio (MSE) e a raiz do erro quadr√°tico m√©dio (RMSE) no conjunto de treinamento.
forest_mse = mean_squared_error(housing_labels, housing_predictions)
forest_rmse = np.sqrt(forest_mse)
print("Forest RMSE (Treinamento):", forest_rmse)

# Observa√ß√£o: O RMSE baixo no treinamento indica que o modelo ajustou bem os dados de treinamento, mas isso 
# n√£o garante que ele generaliza bem para novos dados. Para verificar isso, usamos valida√ß√£o cruzada.

# Valida√ß√£o cruzada com 10 divis√µes para avaliar o desempenho do modelo em diferentes subconjuntos.
forest_scores = cross_val_score(forest_reg, housing_prepared, housing_labels, 
                                scoring="neg_mean_squared_error", cv=10)

# Convertendo os scores negativos para positivos e calculando o RMSE para cada rodada.
forest_rmse_scores = np.sqrt(-forest_scores)

# Exibindo os resultados da valida√ß√£o cruzada.
display_scores(forest_rmse_scores)

# Observa√ß√£o: O modelo de Floresta Aleat√≥ria apresenta um desempenho superior comparado √† Regress√£o Linear
# e √† √Årvore de Decis√£o, com uma m√©dia de RMSE de aproximadamente 50.435 e um desvio padr√£o de 2.203. 
# Isso sugere que o modelo tem uma boa capacidade de generaliza√ß√£o.

# Pontos a considerar:
# - Embora o desempenho da Floresta Aleat√≥ria seja melhor, ainda h√° espa√ßo para melhorias.
# - Ajustes adicionais podem incluir a otimiza√ß√£o dos hiperpar√¢metros (como n√∫mero de estimadores, profundidade m√°xima, etc.)
```

##  Aprimorando o modelo
```
# O Grid Search √© um m√©todo interativo que realiza uma busca exaustiva atrav√©s de todas as combina√ß√µes poss√≠veis 
# de hiperpar√¢metros fornecidos. Isso permite identificar a combina√ß√£o que resulta no melhor desempenho do modelo.

# Definindo a grade de hiperpar√¢metros a ser testada. Cada dicion√°rio representa uma configura√ß√£o poss√≠vel.
param_grid = [
    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},  # Testando diferentes n√∫meros de √°rvores e caracter√≠sticas
    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},  # Testando sem bootstrap e outras combina√ß√µes
]

# Inicializando o GridSearchCV com a Floresta Aleat√≥ria, a grade de par√¢metros e a valida√ß√£o cruzada de 5 divis√µes.
# O crit√©rio de avalia√ß√£o √© o erro quadr√°tico m√©dio negativo (neg_mean_squared_error), o que nos permite otimizar o modelo.
grid_search = GridSearchCV(forest_reg, param_grid, cv=5, scoring='neg_mean_squared_error', return_train_score=True)

# Treinando o GridSearch com os dados de entrada (housing_prepared) e os r√≥tulos (housing_labels).
grid_search.fit(housing_prepared, housing_labels)

# Exibindo os melhores par√¢metros encontrados pelo GridSearch.
print("Melhores par√¢metros encontrados:", grid_search.best_params_)

# Usando os melhores par√¢metros encontrados para treinar o modelo.
forest_reg_1 = RandomForestRegressor(max_features=8, n_estimators=30, random_state=42)
forest_reg_1.fit(housing_prepared, housing_labels)

# Fazendo previs√µes com o modelo otimizado.
housing_predictions = forest_reg_1.predict(housing_prepared)

# Calculando o erro quadr√°tico m√©dio (MSE) e a raiz do erro quadr√°tico m√©dio (RMSE) para as previs√µes.
forest_1mse = mean_squared_error(housing_labels, housing_predictions)
forest_1rmse = np.sqrt(forest_1mse)
print("RMSE ap√≥s ajuste de hiperpar√¢metros:", forest_1rmse)

# Avaliando o desempenho do modelo ajustado com valida√ß√£o cruzada (10 divis√µes).
forest_scores1 = cross_val_score(forest_reg_1, housing_prepared, housing_labels, scoring="neg_mean_squared_error", cv=10)

# Convertendo os scores negativos para positivos e calculando o RMSE para cada rodada da valida√ß√£o cruzada.
forest_rmse_scores1 = np.sqrt(-forest_scores1)

# Exibindo os resultados da valida√ß√£o cruzada com os scores de RMSE.
display_scores(forest_rmse_scores1)

# Observa√ß√£o: Comparando os resultados do modelo original (forest_reg) e do modelo ajustado (forest_reg_1),
# vemos uma melhoria significativa no desempenho. A m√©dia do RMSE diminuiu, e o desvio padr√£o tamb√©m foi reduzido,
# o que indica uma maior precis√£o e maior consist√™ncia nas previs√µes do modelo ajustado.
```

## Avaliando o modelo com o conjunto de teste
 ```
# Inicializando e treinando o modelo com os melhores hiperpar√¢metros encontrados anteriormente
forest_reg_1 = RandomForestRegressor(max_features=8, n_estimators=30, random_state=42)

# Treinando o modelo final com todos os dados de treinamento (housing_prepared e housing_labels)
final_model = forest_reg_1.fit(housing_prepared, housing_labels)

# Preparando os dados de teste (X_test) removendo a coluna "median_house_value" (r√≥tulo)
X_test = strat_test_set.drop("median_house_value", axis=1)

# Extraindo os r√≥tulos reais (y_test), que s√£o os valores da vari√°vel "median_house_value" do conjunto de teste
y_test = strat_test_set["median_house_value"].copy()

# Transformando os dados de teste com o pipeline j√° ajustado (full_pipeline) para garantir que eles tenham o mesmo formato dos dados de treino
X_test_prepared = full_pipeline.transform(X_test)

# Realizando as previs√µes no conjunto de teste utilizando o modelo final treinado
final_predictions = final_model.predict(X_test_prepared)

# Calculando o erro quadr√°tico m√©dio (MSE) para as previs√µes do modelo no conjunto de teste
final_mse = mean_squared_error(y_test, final_predictions)

# Calculando a raiz do erro quadr√°tico m√©dio (RMSE) para avaliar a magnitude do erro
final_rmse = np.sqrt(final_mse)

# Exibindo o RMSE final, que indica a precis√£o do modelo no conjunto de teste
print("RMSE no conjunto de teste:", final_rmse)

# Calculando um intervalo de confian√ßa para os erros quadr√°ticos das previs√µes
# Usamos a distribui√ß√£o t-Student para estimar a confiabilidade dos erros
confidence = 0.95
squared_errors = (final_predictions - y_test) ** 2

# Calculando o intervalo de confian√ßa para o erro quadr√°tico m√©dio das previs√µes
c = np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,
                             loc=squared_errors.mean(),
                             scale=stats.sem(squared_errors)))

# Exibindo o intervalo de confian√ßa (c) para os erros quadr√°ticos das previs√µes
print("Intervalo de confian√ßa para os erros quadr√°ticos:", c)

# Coment√°rio sobre o RMSE obtido no conjunto de teste
# O valor do RMSE √© 47873, o que indica o erro m√©dio das previs√µes do modelo em rela√ß√£o aos valores reais no conjunto de teste.
```

## Salvando o modelo

```
# O 'joblib.dump' √© utilizado para serializar o modelo e armazen√°-lo em disco, permitindo que ele seja carregado novamente em outro momento sem precisar ser re-treinado.

joblib.dump(final_model, "mlcalifornia.pkl")
```
